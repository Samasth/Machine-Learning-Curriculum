{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samasth/Machine-Learning-Curriculum/blob/master/MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "EtEYcrlt58we",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IpwC3YG36Ckm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_h = img_w = 28             # MNIST images are 28x28\n",
        "img_size_flat = img_h * img_w  # 28x28=784, the total number of pixels\n",
        "n_classes = 10                 # Number of classes, one class per digit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JX_5UzMX6LJd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(mode='train'):\n",
        "    \"\"\"\n",
        "    Function to (download and) load the MNIST data\n",
        "    :param mode: train or test\n",
        "    :return: images and the corresponding labels\n",
        "    \"\"\"\n",
        "    from tensorflow.examples.tutorials.mnist import input_data\n",
        "    mnist = tf.keras.datasets.mnist\n",
        "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "    if mode == 'train':\n",
        "        x_train, y_train, x_valid, y_valid = mnist.train.images, mnist.train.labels, \\\n",
        "                                             mnist.validation.images, mnist.validation.labels\n",
        "        return x_train, y_train, x_valid, y_valid\n",
        "    elif mode == 'test':\n",
        "        x_test, y_test = mnist.test.images, mnist.test.labels\n",
        "    return x_test, y_test\n",
        "\n",
        "\n",
        "def randomize(x, y):\n",
        "    \"\"\" Randomizes the order of data samples and their corresponding labels\"\"\"\n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    shuffled_x = x[permutation, :]\n",
        "    shuffled_y = y[permutation]\n",
        "    return shuffled_x, shuffled_y\n",
        "\n",
        "\n",
        "def get_next_batch(x, y, start, end):\n",
        "    x_batch = x[start:end]\n",
        "    y_batch = y[start:end]\n",
        "    return x_batch, y_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F9PD73zu6X3r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "d8e61c57-cad7-4458-eeef-1d3e8ac14187"
      },
      "cell_type": "code",
      "source": [
        "# Load MNIST data\n",
        "x_train, y_train, x_valid, y_valid = load_data(mode='train')\n",
        "print(\"Size of:\")\n",
        "print(\"- Training-set:\\t\\t{}\".format(len(y_train)))\n",
        "print(\"- Validation-set:\\t{}\".format(len(y_valid)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-354b49cb687d>:8: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "Size of:\n",
            "- Training-set:\t\t55000\n",
            "- Validation-set:\t5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k2OSpWg66oe5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3da9244d-baa1-4184-f253-22bfd522c7e5"
      },
      "cell_type": "code",
      "source": [
        "print('x_train:\\t{}'.format(x_train.shape))\n",
        "print('y_train:\\t{}'.format(y_train.shape))\n",
        "print('x_train:\\t{}'.format(x_valid.shape))\n",
        "print('y_valid:\\t{}'.format(y_valid.shape))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train:\t(55000, 784)\n",
            "y_train:\t(55000, 10)\n",
            "x_train:\t(5000, 784)\n",
            "y_valid:\t(5000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wwCq3JhD9U1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "e42852aa-4308-43dc-95ac-ab9ee808472d"
      },
      "cell_type": "code",
      "source": [
        "y_valid[:5, :]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "7mqkrEpx9bnZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Hyper-parameters\n",
        "epochs = 10             # Total number of training epochs\n",
        "batch_size = 100        # Training batch size\n",
        "display_freq = 100      # Frequency of displaying the training results\n",
        "learning_rate = 0.001   # The optimization initial learning rate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2I4fbTal9jSx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weight_variable(shape):\n",
        "    \"\"\"\n",
        "    Create a weight variable with appropriate initialization\n",
        "    :param name: weight name\n",
        "    :param shape: weight shape\n",
        "    :return: initialized weight variable\n",
        "    \"\"\"\n",
        "    initer = tf.truncated_normal_initializer(stddev=0.01)\n",
        "    return tf.get_variable('W',\n",
        "                           dtype=tf.float32,\n",
        "                           shape=shape,\n",
        "                           initializer=initer)\n",
        "\n",
        "\n",
        "def bias_variable(shape):\n",
        "    \"\"\"\n",
        "    Create a bias variable with appropriate initialization\n",
        "    :param name: bias variable name\n",
        "    :param shape: bias variable shape\n",
        "    :return: initialized bias variable\n",
        "    \"\"\"\n",
        "    initial = tf.constant(0., shape=shape, dtype=tf.float32)\n",
        "    return tf.get_variable('b',\n",
        "                           dtype=tf.float32,\n",
        "                           initializer=initial)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D5jCljvC9p8h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create the graph for the linear model\n",
        "# Placeholders for inputs (x) and outputs(y)\n",
        "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='X')\n",
        "y = tf.placeholder(tf.float32, shape=[None, n_classes], name='Y')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AP1ihy2i974A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a8ec2a49-4265-4653-e516-e7d8e21aa7c7"
      },
      "cell_type": "code",
      "source": [
        "# Create weight matrix initialized randomely from N~(0, 0.01)\n",
        "W = weight_variable(shape=[img_size_flat, n_classes])\n",
        "\n",
        "# Create bias vector initialized as zero\n",
        "b = bias_variable(shape=[n_classes])\n",
        "\n",
        "output_logits = tf.matmul(x, W) + b"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fMryiEJD9_14",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "d37630cd-ce8c-4ffb-fbec-368f59e25cd8"
      },
      "cell_type": "code",
      "source": [
        "# Define the loss function, optimizer, and accuracy\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=output_logits), name='loss')\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, name='Adam-op').minimize(loss)\n",
        "correct_prediction = tf.equal(tf.argmax(output_logits, 1), tf.argmax(y, 1), name='correct_pred')\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
        "\n",
        "# Model predictions\n",
        "cls_prediction = tf.argmax(output_logits, axis=1, name='predictions')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-11-ff08d134c349>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xBsiEFsj-H-I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Creating the op for initializing all variables\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wZw7TuVX-Vm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1717
        },
        "outputId": "8a22ed22-c160-4ac6-96a7-9bd21ff8d767"
      },
      "cell_type": "code",
      "source": [
        "# Create an interactive session (to keep the session in the other cells)\n",
        "sess = tf.InteractiveSession()\n",
        "# Initialize all variables\n",
        "sess.run(init)\n",
        "# Number of training iterations in each epoch\n",
        "num_tr_iter = int(len(y_train) / batch_size)\n",
        "for epoch in range(epochs):\n",
        "    print('Training epoch: {}'.format(epoch + 1))\n",
        "    # Randomly shuffle the training data at the beginning of each epoch \n",
        "    x_train, y_train = randomize(x_train, y_train)\n",
        "    for iteration in range(num_tr_iter):\n",
        "        start = iteration * batch_size\n",
        "        end = (iteration + 1) * batch_size\n",
        "        x_batch, y_batch = get_next_batch(x_train, y_train, start, end)\n",
        "\n",
        "        # Run optimization op (backprop)\n",
        "        feed_dict_batch = {x: x_batch, y: y_batch}\n",
        "        sess.run(optimizer, feed_dict=feed_dict_batch)\n",
        "\n",
        "        if iteration % display_freq == 0:\n",
        "            # Calculate and display the batch loss and accuracy\n",
        "            loss_batch, acc_batch = sess.run([loss, accuracy],\n",
        "                                             feed_dict=feed_dict_batch)\n",
        "\n",
        "            print(\"iter {0:3d}:\\t Loss={1:.2f},\\tTraining Accuracy={2:.01%}\".\n",
        "                  format(iteration, loss_batch, acc_batch))\n",
        "\n",
        "    # Run validation after every epoch\n",
        "    feed_dict_valid = {x: x_valid[:1000], y: y_valid[:1000]}\n",
        "    loss_valid, acc_valid = sess.run([loss, accuracy], feed_dict=feed_dict_valid)\n",
        "    print('---------------------------------------------------------')\n",
        "    print(\"Epoch: {0}, validation loss: {1:.2f}, validation accuracy: {2:.01%}\".\n",
        "          format(epoch + 1, loss_valid, acc_valid))\n",
        "    print('---------------------------------------------------------')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training epoch: 1\n",
            "iter   0:\t Loss=2.25,\tTraining Accuracy=26.0%\n",
            "iter 100:\t Loss=0.64,\tTraining Accuracy=91.0%\n",
            "iter 200:\t Loss=0.59,\tTraining Accuracy=83.0%\n",
            "iter 300:\t Loss=0.38,\tTraining Accuracy=95.0%\n",
            "iter 400:\t Loss=0.45,\tTraining Accuracy=90.0%\n",
            "iter 500:\t Loss=0.28,\tTraining Accuracy=92.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 1, validation loss: 0.40, validation accuracy: 88.6%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 2\n",
            "iter   0:\t Loss=0.29,\tTraining Accuracy=90.0%\n",
            "iter 100:\t Loss=0.35,\tTraining Accuracy=92.0%\n",
            "iter 200:\t Loss=0.42,\tTraining Accuracy=90.0%\n",
            "iter 300:\t Loss=0.37,\tTraining Accuracy=88.0%\n",
            "iter 400:\t Loss=0.43,\tTraining Accuracy=90.0%\n",
            "iter 500:\t Loss=0.33,\tTraining Accuracy=95.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 2, validation loss: 0.34, validation accuracy: 89.8%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 3\n",
            "iter   0:\t Loss=0.27,\tTraining Accuracy=91.0%\n",
            "iter 100:\t Loss=0.37,\tTraining Accuracy=90.0%\n",
            "iter 200:\t Loss=0.34,\tTraining Accuracy=92.0%\n",
            "iter 300:\t Loss=0.32,\tTraining Accuracy=90.0%\n",
            "iter 400:\t Loss=0.13,\tTraining Accuracy=99.0%\n",
            "iter 500:\t Loss=0.40,\tTraining Accuracy=91.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 3, validation loss: 0.32, validation accuracy: 90.2%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 4\n",
            "iter   0:\t Loss=0.46,\tTraining Accuracy=88.0%\n",
            "iter 100:\t Loss=0.21,\tTraining Accuracy=95.0%\n",
            "iter 200:\t Loss=0.25,\tTraining Accuracy=91.0%\n",
            "iter 300:\t Loss=0.22,\tTraining Accuracy=92.0%\n",
            "iter 400:\t Loss=0.25,\tTraining Accuracy=93.0%\n",
            "iter 500:\t Loss=0.34,\tTraining Accuracy=92.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 4, validation loss: 0.31, validation accuracy: 90.9%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 5\n",
            "iter   0:\t Loss=0.22,\tTraining Accuracy=93.0%\n",
            "iter 100:\t Loss=0.11,\tTraining Accuracy=97.0%\n",
            "iter 200:\t Loss=0.27,\tTraining Accuracy=93.0%\n",
            "iter 300:\t Loss=0.23,\tTraining Accuracy=93.0%\n",
            "iter 400:\t Loss=0.25,\tTraining Accuracy=93.0%\n",
            "iter 500:\t Loss=0.18,\tTraining Accuracy=94.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 5, validation loss: 0.30, validation accuracy: 91.3%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 6\n",
            "iter   0:\t Loss=0.38,\tTraining Accuracy=92.0%\n",
            "iter 100:\t Loss=0.19,\tTraining Accuracy=95.0%\n",
            "iter 200:\t Loss=0.23,\tTraining Accuracy=92.0%\n",
            "iter 300:\t Loss=0.15,\tTraining Accuracy=96.0%\n",
            "iter 400:\t Loss=0.38,\tTraining Accuracy=94.0%\n",
            "iter 500:\t Loss=0.39,\tTraining Accuracy=89.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 6, validation loss: 0.30, validation accuracy: 91.3%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 7\n",
            "iter   0:\t Loss=0.33,\tTraining Accuracy=89.0%\n",
            "iter 100:\t Loss=0.32,\tTraining Accuracy=91.0%\n",
            "iter 200:\t Loss=0.22,\tTraining Accuracy=94.0%\n",
            "iter 300:\t Loss=0.30,\tTraining Accuracy=93.0%\n",
            "iter 400:\t Loss=0.27,\tTraining Accuracy=89.0%\n",
            "iter 500:\t Loss=0.31,\tTraining Accuracy=93.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 7, validation loss: 0.29, validation accuracy: 91.3%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 8\n",
            "iter   0:\t Loss=0.16,\tTraining Accuracy=96.0%\n",
            "iter 100:\t Loss=0.27,\tTraining Accuracy=93.0%\n",
            "iter 200:\t Loss=0.19,\tTraining Accuracy=95.0%\n",
            "iter 300:\t Loss=0.19,\tTraining Accuracy=97.0%\n",
            "iter 400:\t Loss=0.19,\tTraining Accuracy=94.0%\n",
            "iter 500:\t Loss=0.30,\tTraining Accuracy=90.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 8, validation loss: 0.28, validation accuracy: 91.5%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 9\n",
            "iter   0:\t Loss=0.47,\tTraining Accuracy=86.0%\n",
            "iter 100:\t Loss=0.24,\tTraining Accuracy=93.0%\n",
            "iter 200:\t Loss=0.22,\tTraining Accuracy=90.0%\n",
            "iter 300:\t Loss=0.36,\tTraining Accuracy=86.0%\n",
            "iter 400:\t Loss=0.28,\tTraining Accuracy=93.0%\n",
            "iter 500:\t Loss=0.34,\tTraining Accuracy=94.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 9, validation loss: 0.29, validation accuracy: 91.5%\n",
            "---------------------------------------------------------\n",
            "Training epoch: 10\n",
            "iter   0:\t Loss=0.22,\tTraining Accuracy=94.0%\n",
            "iter 100:\t Loss=0.30,\tTraining Accuracy=90.0%\n",
            "iter 200:\t Loss=0.27,\tTraining Accuracy=94.0%\n",
            "iter 300:\t Loss=0.15,\tTraining Accuracy=96.0%\n",
            "iter 400:\t Loss=0.18,\tTraining Accuracy=94.0%\n",
            "iter 500:\t Loss=0.18,\tTraining Accuracy=94.0%\n",
            "---------------------------------------------------------\n",
            "Epoch: 10, validation loss: 0.28, validation accuracy: 91.6%\n",
            "---------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lSovooOc-d85",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "be2c77a2-332d-4e7d-aadf-34a291023b67"
      },
      "cell_type": "code",
      "source": [
        "# Test the network after training\n",
        "# Accuracy\n",
        "x_test, y_test = load_data(mode='test')\n",
        "feed_dict_test = {x: x_test[:1000], y: y_test[:1000]}\n",
        "loss_test, acc_test = sess.run([loss, accuracy], feed_dict=feed_dict_test)\n",
        "print('---------------------------------------------------------')\n",
        "print(\"Test loss: {0:.2f}, test accuracy: {1:.01%}\".format(loss_test, acc_test))\n",
        "print('---------------------------------------------------------')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "---------------------------------------------------------\n",
            "Test loss: 0.27, test accuracy: 91.9%\n",
            "---------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XDNkuyvL-yDp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n8rreqwo-5wh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}